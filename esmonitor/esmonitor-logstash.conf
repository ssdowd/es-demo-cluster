# This is an example logstash config file that will read monitoring
# endpoints from one Elasticsearch cluster (localhost:9200) and send
# them to another monitoring cluster (localhost:29200).

# Input uses http_pollers to read from ES endpoints.  The names (health
# and stats in this example) will appear in the metadata as
# [http_poller_metadata][name] (used in the index name and doc type in 
# this example [the doc types and template are not defined so they are all
# defaults]).
input {
  http_poller {
    urls => {
      health => {
        method => get
        url => "http://localhost:9200/_cluster/health"
        headers => {
          Accept => "application/json"
        }
      }
      stats => {
        method => get
        url => "http://localhost:9200/_cluster/stats"
        headers => {
          Accept => "application/json"
        }
      }
    }
    # Adjust as needed.
    request_timeout => 60
    interval => 60
    # Write out as json
    codec => "json"
    # A hash of request metadata info (timing, response headers, etc.) will be sent here
    metadata_target => "http_poller_metadata"
  }
}


# Filter as needed here:
filter {
}


# These can be split out by index or by doc type with a template.
# This example uses 2 indices (esstats-health-YYYY.MM.dd and esstats-stats.YYYY.MM.dd)
# The decision to split them depends on how you set up queries in Kibana.  
output {
  stdout { codec => dots }
  
  elasticsearch {
    hosts => [ "localhost:29200" ]
    index => "esstats-%{[http_poller_metadata][name]}-%{+YYYY.MM.dd}"
    document_type => "stat-%{[http_poller_metadata][name]}"
  #  template => "esstats_template.json"
  #  template_name => "esstats"
  }
  
  # Optional: conditionally send to nagios
  if [message] =~ /(error|ERROR|CRITICAL)/ {
    nagios {
      # your config here - see 
      # https://www.elastic.co/guide/en/logstash/current/plugins-outputs-nagios.html
    }
  }
  
}


# vim: set filetype=yaml
